import streamlit as st
import os
import re
import time
from operator import itemgetter
from pathlib import Path
from langchain_classic.retrievers import MultiQueryRetriever
from langchain_core.runnables import RunnablePassthrough, RunnableBranch
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda
from gtts import gTTS
import io
import base64
import hashlib 


TTS_CACHE_DIR = Path("tts_cache/") 
TTS_CACHE_DIR.mkdir(exist_ok=True) 
MAX_RETRIES = 3 
RETRY_DELAY = 5 



CHROMA_DB_DIR = "chroma_db/"
EMBEDDING_MODEL = "paraphrase-multilingual-mpnet-base-v2"
GENERATION_MODEL = "gemini-2.5-flash"
WORD_DATA_SECRET_KEY = "WORD_DATA_CONTENT" 
RATE_LIMIT_SECONDS = 3 


try:
Â  Â  GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
Â  Â  if os.getenv("GEMINI_API_KEY"):
Â  Â  Â  Â  GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
Â  Â  else:
Â  Â  Â  Â  st.error("ERROR: GEMINI API KEY not found. Please check Streamlit Secrets or .env file.")
Â  Â  Â  Â  st.stop()
Â  Â  Â  Â  
if not GEMINI_API_KEY:
Â  Â  st.error("ERROR: GEMINI API KEY could not be loaded.")
Â  Â  st.stop()

try:
Â  Â  hf_token = st.secrets.get("HF_TOKEN")
Â  Â  if hf_token:
Â  Â  Â  Â  os.environ["HUGGINGFACEHUB_API_TOKEN"] = hf_token
except Exception:
Â  Â  pass



def check_rate_limit(session_state):
Â  Â  """
Â  Â  Checks if the minimum time between queries (RATE_LIMIT_SECONDS) has passed.
Â  Â  Returns (True, 0) if allowed, or (False, remaining_time) if restricted.
Â  Â  """
Â  Â  current_time = time.time()
Â  Â  last_query_time = session_state.get("last_query_time", 0)

Â  Â  if current_time - last_query_time < RATE_LIMIT_SECONDS:
Â  Â  Â  Â  remaining_time = RATE_LIMIT_SECONDS - (current_time - last_query_time)
Â  Â  Â  Â  return False, remaining_time
Â  Â  
Â  Â  session_state["last_query_time"] = current_time
Â  Â  return True, 0

def check_prompt_relevance(prompt: str) -> bool:
Â  Â  """
Â  Â  Emulates the 'OffTopicPrompts' guardrail.
Â  Â  Checks if the query contains generic keywords unrelated to translation/language learning.
Â  Â  Returns True if the prompt is relevant, False if it is off-topic.
Â  Â  """
Â  Â  irrelevant_keywords = [
Â  Â  Â  Â  "dÃ¼nyanÄ±n en yÃ¼ksek daÄŸÄ±", "nasÄ±l kod yazÄ±lÄ±r", "hava durumu", 
Â  Â  Â  Â  "kimsin", "kendini tanÄ±t", "tarih", "matematik", "siyaset", 
Â  Â  Â  Â  "tarif", "yemek tarifi", "haberler", "gÃ¼ndem", "ÅŸiir yaz"
Â  Â  ]
Â  Â  
Â  Â  is_word_or_translation_query = any(q in prompt.lower() for q in [
Â  Â  Â  Â  "translate", "Ã§evir", "anlamÄ±", "ne demek", "nedir", "kelime", "cÃ¼mle"
Â  Â  ])
Â  Â  
Â  Â  if len(prompt.split()) > 5 and not is_word_or_translation_query:
Â  Â  Â  Â  if any(keyword in prompt.lower() for keyword in irrelevant_keywords):
Â  Â  Â  Â  Â  Â  return False
Â  Â  Â  Â  Â  Â  
Â  Â  if len(prompt.split()) > 100:
Â  Â  Â  Â  Â return False 

Â  Â  return True



RAG_SYSTEM_PROMPT = """
You are an expert assistant designed for language learning. Your task is to provide the meaning, **ABSOLUTELY THE LEVEL INFORMATION**, and sample sentences for the word queried by the user, **OR** to provide a concise translation for a longer sentence query.

***TASK RULES***

1.**QUERY TYPE CHECK:**
Â  a. **WORD/MEANING QUERY:** If the user's input is a single word or a query asking for the meaning/level of a word (e.g., "what is 'apple'", "elma ne demek"), proceed with RAG and follow Rule 2.
Â  b. **SENTENCE/PHRASE QUERY (NEW):** If the user's input is a full sentence or a longer phrase (generally more than 5 words) that sounds like a translation request, provide only the **direct and concise translation** (English to Turkish or Turkish to English) without applying the RAG context or word format rules.

2.**CONTEXT PRIORITY (RAG for WORD QUERIES ONLY):**
Â  a. If you find a **DIRECT** and **RELIABLE** match for the keyword in the user's query within the 'Context' provided to you, generate your word meaning answer using the information and level from this Context.
Â  b. **LEVEL INFORMATION PRESENTATION (CRITICAL):** Always identify the **'| Level: [Level]'** information explicitly stated in the Context and **MUST** include it in your answer. If the Context does not contain level information (i.e., it's a general translation), **DO NOT INCLUDE** the level information.

3.**LANGUAGE CHECK & FORMAT (Mandatory for WORD QUERIES):** Always start the answer with the format appropriate for the language of the user's query.
Â  **If the query is English,** use the **"English Word Format."**
Â  **If the query is Turkish,** use the **"Turkish Word Format."**
Â  
4.**Sentence Rule (for WORD QUERIES):** For every word you select, construct **at least 3 different correct sample sentences independent of the context** that demonstrate different usage tones of the word. (Sentences must be in the target meaning language, i.e., English sentences for English meaning.)

---
Context:
{context}
---
Question: {input}

***
Sample Answer Formats (Only for Word/Meaning Queries):

# 1. English Word Format (Used if the query is English):
### [English Word] (Level: [Level Information, Exp: A1])
- **Turkish meaning:** [Meaning/Meanings]
- **Sample sentences:**
Â  Â  1. [English Sentence 1]
Â  Â  2. [English Sentence 2]
Â  Â  3. [English Sentence 3]

# 2. Turkish Word Format (Used if the query is Turkish):
### [Turkish Word]
- **English meaning:** [Meaning/Meanings] (Level: [Level Information, Exp: A1])
- **Sample sentences:**
Â  Â  1. [English Sentence 1]
Â  Â  2. [English Sentence 2]
Â  Â  3. [English Sentence 3]
***
"""


@st.cache_resource
def index_data(data_content: str, db_dir: str):
Â  Â  embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
Â  Â  
Â  Â  if Path(db_dir).exists():
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  vectorstore = Chroma(
Â  Â  Â  Â  Â  Â  Â  Â  persist_directory=db_dir, 
Â  Â  Â  Â  Â  Â  Â  Â  embedding_function=embeddings
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  if vectorstore._collection.count() > 0:
Â  Â  Â  Â  Â  Â  Â  Â  return vectorstore
Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  print(e) 
Â  Â  Â  Â  Â  Â  pass
Â  Â  Â  Â  Â  Â  
Â  Â  
Â  Â  with st.spinner("The system is being created, this may take some time, please wait."):
Â  Â  Â  Â  
Â  Â  Â  Â  splits = []
Â  Â  Â  Â  if data_content:
Â  Â  Â  Â  Â  Â  for i, line in enumerate(data_content.splitlines()):
Â  Â  Â  Â  Â  Â  Â  Â  cleaned_line = line.strip()
Â  Â  Â  Â  Â  Â  Â  Â  if cleaned_line:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  splits.append(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Document(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  page_content=cleaned_line,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  metadata={"source": "Custom Dataset", "line": i + 1}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  
Â  Â  Â  Â  if not splits:
Â  Â  Â  Â  Â  Â  raise ValueError(f"The data content from Streamlit Secrets is empty or unreadable.")
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  vectorstore = Chroma.from_documents(
Â  Â  Â  Â  Â  Â  documents=splits, 
Â  Â  Â  Â  Â  Â  embedding=embeddings,
Â  Â  Â  Â  Â  Â  persist_directory=db_dir 
Â  Â  Â  Â  )
Â  Â  Â  Â  
Â  Â  return vectorstore

def format_context_with_level(docs: list[Document]) -> str:
Â  Â  """
Â  Â  Processes documents (docs) coming from the Retriever.
Â  Â  Captures level information (A1, B2, etc.), separates it from the content, and
Â  Â  creates an explicitly labeled format for the model to see: [CONTENT] | Level: [LEVEL]
Â  Â  """
Â  Â  formatted_docs = []

Â  Â  level_pattern = re.compile(r'\s+([A-C1-2]{1,2})$') 

Â  Â  for i, doc in enumerate(docs):
Â  Â  Â  Â  content = doc.page_content.strip()
Â  Â  Â  Â  match = level_pattern.search(content)
Â  Â  Â  Â  
Â  Â  Â  Â  if match:
Â  Â  Â  Â  Â  Â  level = match.group(1)
Â  Â  Â  Â  Â  Â  cleaned_content = content[:match.start()].strip()
Â  Â  Â  Â  Â  Â  formatted_line = f"[DATASET WORD {i+1}] {cleaned_content} | Level: {level}"
Â  Â  Â  Â  Â  Â  formatted_docs.append(formatted_line)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  formatted_docs.append(f"[GENERAL CONTEXT {i+1}] {content}") 
Â  Â  Â  Â  Â  Â  
Â  Â  return "\n---\n".join(formatted_docs)

def is_rag_query(query_dict: dict) -> bool:Â  Â  
Â  Â  """
Â  Â  Checks whether the query is a word translation/meaning/level query (RAG) 
Â  Â  or a general question/sentence translation (NON-RAG/LLM-only).
Â  Â  RAG is used for word lookups to include level information from the dataset.
Â  Â  Sentence translation or general questions rely purely on the LLM.
Â  Â  """
Â  Â  query = query_dict["input"].lower()

Â  Â  is_word_query_keywords = any(q in query for q in ["meaning of", "what is", "word", "level of", "give me", "translation of", "translate","ne demek","nedir","kelimesini","seviyesini","ver","anlamÄ±","Ã§evir"])
Â  Â  is_short_query = len(query.split()) <= 5

Â  Â  if is_word_query_keywords or (is_short_query and not is_word_query_keywords):
Â  Â  Â  Â  return True
Â  Â  
Â  Â  return False


def extract_english_word(model_response: str, query: str) -> str:
Â  Â  """
Â  Â  It extracts the English word(s) to be vocalized from the model's response.
Â  Â  It collects all English words from the titles (Format 1) or from the 'English meaning' lines (Format 2).
Â  Â  
Â  Â  It also checks if the response is a direct sentence translation 
Â  Â  (i.e., not matching the word formats) and if the original query was Turkish, 
Â  Â  it vocalizes the entire translated English sentence.
Â  Â  """
Â  Â  
Â  Â  english_words_to_speak = set()
Â  Â  
Â  Â  for match_header in re.finditer(r"^###\s+([^#\n]+)\s*\(Level:\s*[A-C1-2]{1,2}\)", model_response, re.MULTILINE):
Â  Â  Â  Â  header_content = match_header.group(1).strip()
Â  Â  Â  Â  
Â  Â  Â  Â  raw_english_words = re.sub(r'\s*\([^)]*\)', '', header_content).strip()
Â  Â  Â  Â  
Â  Â  Â  Â  words = re.findall(r'[a-zA-Z\s\-]+', raw_english_words)
Â  Â  Â  Â  for w in words:
Â  Â  Â  Â  Â  Â  clean_word = w.strip().lower()
Â  Â  Â  Â  Â  Â  if clean_word and len(clean_word.split()) <= 5: 
Â  Â  Â  Â  Â  Â  Â  Â  english_words_to_speak.add(clean_word)

Â  Â  
Â  Â  for match_meaning in re.finditer(r"^\s*-\s*\*\*English meaning:\*\*\s*([^(\n]+)", model_response, re.MULTILINE):
Â  Â  Â  Â  meaning_text = match_meaning.group(1).strip()
Â  Â  Â  Â  
Â  Â  Â  Â  meaning_groups = re.split(r'[,;]+', meaning_text) 
Â  Â  Â  Â  
Â  Â  Â  Â  for group in meaning_groups:
Â  Â  Â  Â  Â  Â  segment = group.strip()
Â  Â  Â  Â  Â  Â  clean_segment = re.sub(r'[^a-zA-Z\s\-]', '', segment).strip() 
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  if clean_segment:
Â  Â  Â  Â  Â  Â  Â  Â  clean_word = clean_segment.lower()
Â  Â  Â  Â  Â  Â  Â  Â  if len(clean_word.split()) <= 5: 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  english_words_to_speak.add(clean_word)
Â  Â  
Â  Â  
Â  Â  if not english_words_to_speak:
Â  Â  Â  Â  if any(c in query for c in ['Ä±', 'ÄŸ', 'Ã¼', 'ÅŸ', 'Ã¶', 'Ã§']):
Â  Â  Â  Â  Â  Â  if re.match(r'^[a-zA-Z\s\.,\'"?!]+$', model_response.strip()):
Â  Â  Â  Â  Â  Â  Â  Â  return model_response.strip().lower()

Â  Â  if english_words_to_speak:
Â  Â  Â  Â  return ", ".join(sorted(list(english_words_to_speak)))

Â  Â  return ""


GENERAL_SYSTEM_PROMPT = "You are a helpful and knowledgeable assistant. Answer the user's general question concisely. If the input is a sentence translation request (e.g., 'elma almam gerekiyor'), provide ONLY the direct and concise translation (e.g., 'I need to buy an apple.') without any extra explanation or formatting."

@st.cache_resource
def create_rag_chain(_vectorstore: Chroma):
Â  Â  with st.spinner(f"Establishing RAG Chain and Multiple Query ({GENERATION_MODEL})..."):
Â  Â  Â  Â  
Â  Â  Â  Â  llm = ChatGoogleGenerativeAI(
Â  Â  Â  Â  Â  Â  model=GENERATION_MODEL, 
Â  Â  Â  Â  Â  Â  temperature=0.7, 
Â  Â  Â  Â  Â  Â  google_api_key=GEMINI_API_KEY
Â  Â  Â  Â  )

Â  Â  Â  Â  
Â  Â  Â  Â  multiquery_retriever = MultiQueryRetriever.from_llm(
Â  Â  Â  Â  Â  Â  retriever=_vectorstore.as_retriever(search_kwargs={"k": 3}),
Â  Â  Â  Â  Â  Â  llm=llm
Â  Â  Â  Â  )

Â  Â  Â  Â  
Â  Â  Â  Â  rag_prompt = ChatPromptTemplate.from_messages([
Â  Â  Â  Â  Â  Â  ("system", RAG_SYSTEM_PROMPT),
Â  Â  Â  Â  Â  Â  ("human", "{input}")
Â  Â  Â  Â  ])
Â  Â  Â  Â  
Â  Â  Â  Â  
Â  Â  Â  Â  general_prompt = ChatPromptTemplate.from_messages([
Â  Â  Â  Â  Â  Â  ("system", GENERAL_SYSTEM_PROMPT),
Â  Â  Â  Â  Â  Â  ("human", "{input}")
Â  Â  Â  Â  ])
Â  Â  Â  Â  
Â  Â  Â  Â  
Â  Â  Â  Â  rag_chain_with_context_formatting = ( 
Â  Â  Â  Â  Â  Â  RunnablePassthrough.assign(
Â  Â  Â  Â  Â  Â  Â  Â  context=itemgetter("input") | multiquery_retriever | RunnableLambda(format_context_with_level) 
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  | rag_prompt
Â  Â  Â  Â  Â  Â  | llm
Â  Â  Â  Â  Â  Â  | StrOutputParser()
Â  Â  Â  Â  )

Â  Â  Â  Â  
Â  Â  Â  Â  final_chain = (
Â  Â  Â  Â  Â  Â  RunnableBranch(
Â  Â  Â  Â  Â  Â  Â  Â  (RunnableLambda(is_rag_query), rag_chain_with_context_formatting), 
Â  Â  Â  Â  Â  Â  Â  Â  (itemgetter("input") | general_prompt | llm | StrOutputParser()),
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  )
Â  Â  Â  Â  
Â  Â  st.success("RAG Chain (with Dataset + General Translation Support) was established.") 
Â  Â  return final_chain 

def main():
Â  Â  st.set_page_config(page_title="Translation Bot", layout="wide")
Â  Â  st.title("Dynamic RAG-Powered Translation Bot (with Sentence Translation and Voice-over)")
Â  Â  
Â  Â  data_content = None
Â  Â  data_source_name = "Streamlit Secrets"
Â  Â  
Â  Â  if "data_storage" in st.secrets and WORD_DATA_SECRET_KEY in st.secrets["data_storage"]:
Â  Â  Â  Â  Â  data_content = st.secrets["data_storage"][WORD_DATA_SECRET_KEY]
Â  Â  Â  Â  Â  #st.caption(f"Data Source: **{data_source_name}** (`[data_storage]` table)")
Â  Â  
Â  Â  if not data_content:
Â  Â  Â  Â  st.error(f"CRITICAL ERROR: The table **'[data_storage]'** or its key **'{WORD_DATA_SECRET_KEY}'** could not be found in Streamlit Secrets, or the content is empty. The application cannot be started. Please check your '.streamlit/secrets.toml' file.")
Â  Â  Â  Â  return

Â  Â  try:
Â  Â  Â  Â  _vectorstore = index_data(data_content, CHROMA_DB_DIR)
Â  Â  Â  Â  rag_chain = create_rag_chain(_vectorstore)
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"A critical error occurred during system installation (Indexing or RAG Chain creation): {e}")
Â  Â  Â  Â  return

Â  Â  
Â  Â  info_text = f"""
Â  Â  ## ðŸ“š Welcome to your English-Turkish Language Teaching Assistant!
Â  Â  
Â  Â  This smart bot is designed for language learning and translation. It responds in two different modes depending on your query type:
Â  Â  
Â  Â  ### 1. ðŸ” Vocabulary Queries (Level-Aware)
Â  Â  * **Query:** The meaning, level, or usage of a word.
Â  Â  * **Answer:** Includes **level information (A1, B2, etc.)**, its meaning, and 3 example sentences from our proprietary database.
Â  Â  * **Example:** `What does execute mean?`
Â  Â  
Â  Â  ### 2. ðŸ’¬ Sentence Translation (Quick Response)
Â  Â  * **Query:** Translates a long sentence.
Â  Â  * **Answer:** Provides a quick and direct translation, skipping RAG steps.
Â  Â  * **Example:** `I don't want to be late for the meeting tomorrow.`
Â  Â  
Â  Â  
Â  Â  ### âœ¨ Additional Features
Â  Â  * **Read Aloud:** All English output is automatically converted to audio.
Â  Â  
Â  Â  ### ðŸ›¡ï¸ Usage Notes
Â  Â  * **Topic Restriction:** The bot only responds to questions related to **translation and language learning**. (General topics are blocked.)
Â  Â  * **Speed Throttling:** To maintain API quota consumption, you must wait **{RATE_LIMIT_SECONDS} seconds** between consecutive queries.

Â  Â  ---
Â  Â  """
Â  Â  
Â  Â  st.markdown(info_text)


Â  Â  if "messages" not in st.session_state:
Â  Â  Â  Â  st.session_state.messages = []
Â  Â  
Â  Â  if "last_query_time" not in st.session_state:
Â  Â  Â  Â  st.session_state["last_query_time"] = 0


Â  Â  for message in st.session_state.messages:
Â  Â  Â  Â  with st.chat_message(message["role"]):
Â  Â  Â  Â  Â  Â  content = message["content"]
Â  Â  Â  Â  Â  Â  st.markdown(content)
Â  Â  Â  Â  Â  Â  
Â  Â  if prompt := st.chat_input("Ask for a word or a sentence to be translated..."):
Â  Â  Â  Â  
Â  Â  Â  Â  is_allowed, remaining_time = check_rate_limit(st.session_state)
Â  Â  Â  Â  if not is_allowed:
Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ **Too Fast!** Please wait **{remaining_time:.2f}** seconds before sending a new query to protect API usage.")
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  
Â  Â  Â  Â  if not check_prompt_relevance(prompt):
Â  Â  Â  Â  Â  Â  st.error("âŒ **Prompt Blocked:** Your query is outside the scope of translation and language learning. Please ask questions related only to word meanings, sentence translations, or language assistance.")
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  
Â  Â  Â  Â  timestamp = st.session_state.get("message_counter", 0) + 1
Â  Â  Â  Â  st.session_state["message_counter"] = timestamp
Â  Â  Â  Â  
Â  Â  Â  Â  st.session_state.messages.append({"role": "user", "content": prompt, "timestamp": timestamp})
Â  Â  Â  Â  with st.chat_message("user"):
Â  Â  Â  Â  Â  Â  st.markdown(prompt)

Â  Â  Â  Â  with st.chat_message("assistant"):
Â  Â  Â  Â  Â  Â  assistant_response_container = st.empty()
Â  Â  Â  Â  Â  Â  with st.spinner("The answer is being sought and created..."):
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  input_data = {"input": prompt}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  result = rag_chain.invoke(input_data)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  assistant_response_container.markdown(result)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  english_words_to_speak = extract_english_word(result, prompt)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if english_words_to_speak:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cache_key = hashlib.sha256(english_words_to_speak.encode('utf-8')).hexdigest()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cache_file = TTS_CACHE_DIR / f"{cache_key}.mp3"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  audio_bytes = None
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if cache_file.exists():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with open(cache_file, "rb") as f:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  audio_bytes = f.read()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tts_success = False

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for attempt in range(MAX_RETRIES):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tts = gTTS(text=english_words_to_speak, lang='en', slow=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mp3_fp = io.BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tts.write_to_fp(mp3_fp)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mp3_fp.seek(0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  audio_bytes = mp3_fp.read()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with open(cache_file, "wb") as f:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f.write(audio_bytes)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tts_success = True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception as tts_e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  error_message = str(tts_e)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if "Too Many Requests" in error_message or "429" in error_message:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if attempt < MAX_RETRIES - 1:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ **TTS API Restriction (429).** {attempt + 1}th attempt failed. Waiting for {RETRY_DELAY} seconds...")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(RETRY_DELAY)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"âŒ Audio generation failed on {MAX_RETRIES} attempts. Detail: {tts_e}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"âŒ Unexpected Audio Rendering Error: {tts_e}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if audio_bytes:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â audio_html = f"""
                            <audio controls controlsList="nodownload" style="width: 150px; height: 30px;">
                                <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
                            </audio>
                            """
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(audio_html, unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if len(english_words_to_speak.split()) > 5:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  caption_text = "Vocalized sentence"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  caption_text = "Vocalized word(s)"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.caption(f"{caption_text}: **{english_words_to_speak[:100]}{'...' if len(english_words_to_speak) > 100 else ''}**")
Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.messages.append({"role": "assistant", "content": result, "timestamp": timestamp})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  error_msg = f"A critical error occurred while generating the response: {e}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(error_msg)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.messages.append({"role": "assistant", "content": error_msg, "timestamp": timestamp})

if __name__ == "__main__":
Â  Â  main()
